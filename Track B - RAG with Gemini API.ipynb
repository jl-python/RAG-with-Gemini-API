{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Track B: RAG with Gemini API**\n",
        "#### This notebook demonstrates a Retrieval-Augmented Generation (RAG) pipeline using Google Gemini API and LangChain.\n"
      ],
      "metadata": {
        "id": "4k0nOuKeLbVZ"
      },
      "id": "4k0nOuKeLbVZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set Up"
      ],
      "metadata": {
        "id": "al-rHG-oSko5"
      },
      "id": "al-rHG-oSko5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2cfbf2ed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cfbf2ed",
        "outputId": "96a9f08a-38fe-4be0-8330-a5f961277ca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API key loaded from Colab Secrets\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "Documents found ['Chess GPT Paper.pdf', 'Maia-2 Paper.pdf', 'Chess Bench with Stockfish Paper.pdf']\n",
            "\n",
            "Loaded 99 documents from 3 PDFs.\n",
            "\n",
            "Saved reproduce_artifacts/env_rag.json\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Installs\n",
        "!pip install -q google-generativeai langchain langchain-community langchain-google-genai chromadb pypdf sentence-transformers\n",
        "\n",
        "\n",
        "\n",
        "# API Key Setup\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "\n",
        "\n",
        "# Colab automatically injects Secrets API Key into the environment\n",
        "api_key = os.environ.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "if not api_key:\n",
        "    api_key = getpass.getpass(f'Please input GOOGLE_API_KEY: ')\n",
        "\n",
        "\n",
        "\n",
        "# Make sure both env vars are aligned\n",
        "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
        "os.environ[\"GENAI_API_KEY\"] = api_key\n",
        "\n",
        "print(\"API key loaded from Colab Secrets\")\n",
        "\n",
        "\n",
        "\n",
        "# Document Loading\n",
        "import os\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "pdf_path = \"/content/drive/My Drive/Capstone/Academic Papers\"\n",
        "\n",
        "print(f'\\nDocuments found {os.listdir(pdf_path)}')\n",
        "\n",
        "docs = []\n",
        "\n",
        "for file in os.listdir(pdf_path):\n",
        "    if file.endswith('.pdf'):\n",
        "      loader = PyPDFLoader(os.path.join(pdf_path, file))\n",
        "      docs.extend(loader.load())\n",
        "\n",
        "print(f\"\\nLoaded {len(docs)} documents from {len(os.listdir(pdf_path))} PDFs.\")\n",
        "\n",
        "\n",
        "\n",
        "# env_rag.json creation\n",
        "\n",
        "import importlib, json, os\n",
        "os.makedirs(\"reproduce_artifacts\", exist_ok=True)\n",
        "\n",
        "def get_version(pkg, import_name=None):\n",
        "    try:\n",
        "        mod = importlib.import_module(import_name or pkg)\n",
        "        return getattr(mod, \"__version__\", \"unknown\")\n",
        "    except ImportError:\n",
        "        return \"not installed\"\n",
        "\n",
        "env_rag = {\n",
        "    \"python\": \"3.10.12\",\n",
        "    \"packages\": {\n",
        "        \"torch\": get_version(\"torch\"),\n",
        "        \"transformers\": get_version(\"transformers\"),\n",
        "        \"sentence-transformers\": get_version(\"sentence_transformers\"),\n",
        "        \"chromadb\": get_version(\"chromadb\"),\n",
        "        \"langchain\": get_version(\"langchain\"),\n",
        "        \"langchain-community\": get_version(\"langchain_community\"),\n",
        "        \"langchain-google-genai\": get_version(\"langchain_google_genai\"),\n",
        "        \"google-generativeai\": get_version(\"google.generativeai\"),\n",
        "        \"pypdf\": get_version(\"pypdf\"),\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(\"reproduce_artifacts/env_rag.json\", \"w\") as f:\n",
        "    json.dump(env_rag, f, indent=2)\n",
        "\n",
        "print(\"\\nSaved reproduce_artifacts/env_rag.json\")\n",
        "\n",
        "\n",
        "\n",
        "# Function for Q&A for LLM model and organized outputs for json file\n",
        "def ask(q):\n",
        "    r = qa.invoke({\"query\": q})\n",
        "    answer = r.get(\"result\", \"\")\n",
        "    raw_sources = [d.metadata.get(\"source\", \"?\") for d in r.get(\"source_documents\", [])]\n",
        "\n",
        "    # Only keep the filename (or whatever part you want exposed)\n",
        "    sources = [os.path.basename(s) for s in raw_sources if s]\n",
        "\n",
        "    print(\"\\nQ:\", q)\n",
        "    print(\"A:\", answer)\n",
        "    print(\"\\nSources:\")\n",
        "    for i, d in enumerate(r.get(\"source_documents\", [])[:3]):\n",
        "        fname = os.path.basename(d.metadata.get(\"source\",\"?\"))\n",
        "        print(f\"[{i+1}] {fname} ::\", d.page_content[:160].replace(\"\\n\",\" \")+\"...\")\n",
        "\n",
        "    return {\"question\": q, \"answer\": answer, \"sources\": sources}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment: MiniLM | chunk_size=500, overlap=100\n"
      ],
      "metadata": {
        "id": "o_gzt9DUGt0y"
      },
      "id": "o_gzt9DUGt0y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18049bbb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18049bbb",
        "outputId": "e351fc3e-5a17-44a1-f03e-9dcd348fa4ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved reproduce_artifacts/rag_run_config_minilm_500_100.json\n"
          ]
        }
      ],
      "source": [
        "# Experiment: MiniLM | chunk_size=500, overlap=100\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "import google.generativeai as genai\n",
        "import os, getpass, pathlib\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "splits = splitter.split_documents(docs)\n",
        "emb = SentenceTransformerEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "vs = Chroma.from_documents(splits, embedding=emb, persist_directory=\"./chroma_minilm_500_100\")\n",
        "retriever = vs.as_retriever()\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.2, google_api_key=os.environ['GOOGLE_API_KEY'])\n",
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True)\n",
        "\n",
        "\n",
        "rag_run_config = {\n",
        "    \"chunk_size\": 500,\n",
        "    \"chunk_overlap\": 100,\n",
        "    \"embedding_model\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    \"llm\": \"gemini-2.5-flash\",\n",
        "    \"retriever_k\": 4\n",
        "}\n",
        "\n",
        "filename = \"reproduce_artifacts/rag_run_config_minilm_500_100.json\"\n",
        "with open(filename, \"w\") as f:\n",
        "    json.dump(rag_run_config, f, indent=2)\n",
        "print(f\"Saved {filename}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c67629f8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c67629f8",
        "outputId": "38261863-4a39-4723-f819-45b8c1456813"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Q: What role does Stockfish 16 play in annotating the ChessBench dataset, and how do these annotations support amortized planning models in learning better policies?\n",
            "A: Based on the provided context, Stockfish 16 is mentioned as a point of comparison for the models, ablations, and searchless policy/value networks, alongside Leela Chess Zero and AlphaZero.\n",
            "\n",
            "The text does not state that Stockfish 16 plays a role in annotating the ChessBench dataset, nor does it describe how such annotations would support amortized planning models in learning better policies. The details regarding dataset creation are referred to Appendix A, which is not provided here.\n",
            "\n",
            "Sources:\n",
            "[1] Chess Bench with Stockfish Paper.pdf :: series of benchmark results through our models, ablations, and comparisons with Stock- fish 16, Leela Chess Zero, and AlphaZero, and their searchless policy/val...\n",
            "[2] Chess Bench with Stockfish Paper.pdf :: series of benchmark results through our models, ablations, and comparisons with Stock- fish 16, Leela Chess Zero, and AlphaZero, and their searchless policy/val...\n",
            "[3] Chess Bench with Stockfish Paper.pdf :: of moves. Bottom right (Policies): We train predictors on three targets (state- or action-values, or oracle actions), each of which can be used for a chess poli...\n",
            "\n",
            "Q: How does Maia-2’s skill-aware attention mechanism adjust move predictions when modeling players of different skill levels?\n",
            "A: Maia-2’s skill-aware attention mechanism enables it to adapt its move predictions by accounting for the skill levels of both the active player and the opponent player. This allows for varying skill level configurations to result in better aligned human move predictions.\n",
            "\n",
            "Sources:\n",
            "[1] Maia-2 Paper.pdf :: with skill-aware attention enables Maia-2 to adapt its predictions to account for the skill levels of both the active player and the opponent player, so that va...\n",
            "[2] Maia-2 Paper.pdf :: with skill-aware attention enables Maia-2 to adapt its predictions to account for the skill levels of both the active player and the opponent player, so that va...\n",
            "[3] Maia-2 Paper.pdf :: effectiveness of our unified modeling approach across diverse skill levels. Adaptive move predictions. We now evaluate Maia-2’s ability to predict compare acros...\n",
            "\n",
            "Q: What types of datasets were used to train ChessGPT, and how do the game, language, and mixed datasets each contribute to improving its performance?\n",
            "A: Based on the provided context:\n",
            "\n",
            "*   **Types of datasets used to train ChessGPT:** The context explicitly mentions a \"chess-specific language dataset\" (Table 10) and refers to ChessGPT being \"trained on our database.\" Table 9 also indicates a \"dataset statistics breakdown for each data subset,\" implying multiple subsets, but their specific names (like \"game,\" \"language,\" or \"mixed\") are not detailed in the provided snippets.\n",
            "\n",
            "*   **How game, language, and mixed datasets each contribute to improving its performance:** The provided text does not explain how \"game,\" \"language,\" or \"mixed\" datasets specifically contribute to improving ChessGPT's performance. It only states that ChessGPT's performance is assessed in three primary dimensions: \"Chess modeling ability,\" \"Value judgement ability,\" and \"Policy ability.\" The \"Chess Modeling capability\" focuses on the model's proficiency in accurately tracking the game. The contribution of specific dataset types to these abilities is not described.\n",
            "\n",
            "Sources:\n",
            "[1] Chess GPT Paper.pdf :: • Value judgement: https://www.thenewatlantis.com/wp-content/uploads/legacy/20190820_TNA58Wilkenfeldbanner.jpg D Dataset analysis D.1 Dataset statistics and met...\n",
            "[2] Chess GPT Paper.pdf :: • Value judgement: https://www.thenewatlantis.com/wp-content/uploads/legacy/20190820_TNA58Wilkenfeldbanner.jpg D Dataset analysis D.1 Dataset statistics and met...\n",
            "[3] Chess GPT Paper.pdf :: 5 Evaluation and benchmark In this section, we present a comparative analysis between ChessGPT trained on our database with other baseline LLMs. The purpose of ...\n",
            "Saved logs/results_minilm_500_100.json\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "q1 = ask(\"What role does Stockfish 16 play in annotating the ChessBench dataset, and how do these annotations support amortized planning models in learning better policies?\")  # ChessBench\n",
        "\n",
        "q2 = ask(\"How does Maia-2’s skill-aware attention mechanism adjust move predictions when modeling players of different skill levels?\")  # Maia-2\n",
        "\n",
        "q3 = ask(\"What types of datasets were used to train ChessGPT, and how do the game, language, and mixed datasets each contribute to improving its performance?\")  # ChessGPT\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "\n",
        "os.makedirs(\"logs\", exist_ok=True)\n",
        "with open('logs/results_minilm_500_100.json', 'w') as f:\n",
        "    json.dump([q1, q2, q3], f, indent=2)\n",
        "print('Saved logs/results_minilm_500_100.json')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment: MiniLM | chunk_size=300, overlap=50\n"
      ],
      "metadata": {
        "id": "2y5C5iWwGZXa"
      },
      "id": "2y5C5iWwGZXa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bcfb663",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bcfb663",
        "outputId": "320a8aa6-5f84-4791-839a-b15a3129956d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved reproduce_artifacts/rag_run_config_minilm_300_50.json\n"
          ]
        }
      ],
      "source": [
        "# Experiment: MiniLM | chunk_size=300, overlap=50\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "import google.generativeai as genai\n",
        "import os, getpass, pathlib\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
        "splits = splitter.split_documents(docs)\n",
        "emb = SentenceTransformerEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "vs = Chroma.from_documents(splits, embedding=emb, persist_directory=\"./chroma_minilm_300_50\")\n",
        "retriever = vs.as_retriever()\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.2, google_api_key=os.environ['GOOGLE_API_KEY'])\n",
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True)\n",
        "\n",
        "\n",
        "\n",
        "rag_run_config = {\n",
        "    \"chunk_size\": 300,\n",
        "    \"chunk_overlap\": 50,\n",
        "    \"embedding_model\": \"sentence-transformers/all-MiniLM-L6-v2\",\n",
        "    \"llm\": \"gemini-2.5-flash\",\n",
        "    \"retriever_k\": 4\n",
        "}\n",
        "\n",
        "filename = \"reproduce_artifacts/rag_run_config_minilm_300_50.json\"\n",
        "with open(filename, \"w\") as f:\n",
        "    json.dump(rag_run_config, f, indent=2)\n",
        "print(f\"Saved {filename}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "q1 = ask(\"What role does Stockfish 16 play in annotating the ChessBench dataset, and how do these annotations support amortized planning models in learning better policies?\")  # ChessBench\n",
        "\n",
        "q2 = ask(\"How does Maia-2’s skill-aware attention mechanism adjust move predictions when modeling players of different skill levels?\")  # Maia-2\n",
        "\n",
        "q3 = ask(\"What types of datasets were used to train ChessGPT, and how do the game, language, and mixed datasets each contribute to improving its performance?\")  # ChessGPT\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "\n",
        "os.makedirs(\"logs\", exist_ok=True)\n",
        "with open('logs/results_minilm_300_50.json', 'w') as f:\n",
        "    json.dump([q1, q2, q3], f, indent=2)\n",
        "print('Saved logs/results_minilm_300_50.json')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeyuIHeTUUJ0",
        "outputId": "5cedab21-d136-4dc6-e4c6-2fb75f84139e"
      },
      "id": "HeyuIHeTUUJ0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Q: What role does Stockfish 16 play in annotating the ChessBench dataset, and how do these annotations support amortized planning models in learning better policies?\n",
            "A: Based on the provided context:\n",
            "\n",
            "*   The text mentions that ChessBench shows the feasibility of \"distilling an approximation of Stockfish 16, a complex planning algorithm.\" However, it **does not state that Stockfish 16 plays a role in annotating the ChessBench dataset.**\n",
            "*   The context mentions \"annotation language\" (Lt) is paired with chessboard states (St) to train a ChessCLIP model to \"bridge the modality of policy and language.\" While this suggests annotations support policy learning, the text **does not explain how these annotations specifically support \"amortized planning models in learning better policies,\" nor does it link this process back to Stockfish 16.**\n",
            "\n",
            "Sources:\n",
            "[1] Chess Bench with Stockfish Paper.pdf :: 6 Conclusion Our paper introduces ChessBench, a large-scale, open source benchmark dataset for chess, and shows the feasibility of distilling an approximation o...\n",
            "[2] Chess Bench with Stockfish Paper.pdf :: 2 Methodology We now describe the dataset creation, the neural predictors and how to construct policies from them, and our evaluation methodology (see Figure 1 ...\n",
            "[3] Chess GPT Paper.pdf :: structure because the annotation is naturally paired with its preceding game trajectories. Based on this subset, we can train a ChessCLIP to bridge the modality...\n",
            "\n",
            "Q: How does Maia-2’s skill-aware attention mechanism adjust move predictions when modeling players of different skill levels?\n",
            "A: Maia-2’s skill-aware attention mechanism adjusts move predictions by adapting its focus to reflect the strategic considerations and positional understanding of players at different skill levels. This allows it to adaptively prioritize features of the positions that are more relevant to the specific skill level configuration of both the active player and the opponent.\n",
            "\n",
            "Sources:\n",
            "[1] Maia-2 Paper.pdf :: with skill-aware attention enables Maia-2 to adapt its predictions to account for the skill levels of both the active player and the opponent player, so that va...\n",
            "[2] Maia-2 Paper.pdf :: k, the attention mechanism can adjust its focus to reflect the strategic considerations and positional understanding of players at different skill levels. This ...\n",
            "[3] Maia-2 Paper.pdf :: Adaptive move predictions. We now evaluate Maia-2’s ability to predict compare across diverse skill combinations using the Cross-skill Testset. As shown in Figu...\n",
            "\n",
            "Q: What types of datasets were used to train ChessGPT, and how do the game, language, and mixed datasets each contribute to improving its performance?\n",
            "A: Based on the provided context, the following types of datasets were used to train ChessGPT:\n",
            "\n",
            "1.  **Chess-specific language dataset:** Mentioned in Table 10 as being used for training ChessGPT.\n",
            "2.  **Mixed game-language dataset:** Established from around 83k chess videos, resulting in million-scale English transcripts and board-language pairs.\n",
            "3.  **Instruction-tuning & conversation dataset:** Mentioned as a section heading (3.4), indicating its use.\n",
            "\n",
            "The provided text states that these datasets were used for training ChessGPT, but it **does not elaborate on how the game, language, and mixed datasets each specifically contribute to improving its performance.**\n",
            "\n",
            "Sources:\n",
            "[1] Chess GPT Paper.pdf :: D.1 Dataset statistics and metrics InTable 9, we present the dataset statistics breakdown for each data subset, including its raw size, document count, and subs...\n",
            "[2] Chess GPT Paper.pdf :: 5 Evaluation and benchmark In this section, we present a comparative analysis between ChessGPT trained on our database with other baseline LLMs. The purpose of ...\n",
            "[3] Chess GPT Paper.pdf :: format. We gathered around 83k chess videos, resulting in million-scale English transcripts and board-language pairs, thus establishing a substantial mixed game...\n",
            "Saved logs/results_minilm_300_50.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment: Gemini Embedding 001 | chunk_size=500, overlap=100\n"
      ],
      "metadata": {
        "id": "OldEYQ_iGS0p"
      },
      "id": "OldEYQ_iGS0p"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeeab05f",
      "metadata": {
        "id": "aeeab05f"
      },
      "outputs": [],
      "source": [
        "# Experiment: e5-small-v2 | chunk_size=500, overlap=100\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "import google.generativeai as genai\n",
        "import os, getpass, pathlib\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "splits = splitter.split_documents(docs)\n",
        "emb = SentenceTransformerEmbeddings(model_name=\"intfloat/e5-small-v2\")\n",
        "vs = Chroma.from_documents(splits, embedding=emb, persist_directory=\"./chroma_gemini_500_100\")\n",
        "retriever = vs.as_retriever()\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.2, google_api_key=os.environ['GOOGLE_API_KEY'])\n",
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True)\n",
        "\n",
        "\n",
        "rag_run_config = {\n",
        "    \"chunk_size\": 500,\n",
        "    \"chunk_overlap\": 100,\n",
        "    \"embedding_model\": \"intfloat/e5-small-v2\",\n",
        "    \"llm\": \"gemini-2.5-flash\",\n",
        "    \"retriever_k\": 4\n",
        "}\n",
        "\n",
        "filename = \"reproduce_artifacts/rag_run_config_e5small_500_100.json\"\n",
        "with open(filename, \"w\") as f:\n",
        "    json.dump(rag_run_config, f, indent=2)\n",
        "print(f\"Saved {filename}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "q1 = ask(\"What role does Stockfish 16 play in annotating the ChessBench dataset, and how do these annotations support amortized planning models in learning better policies?\")  # ChessBench\n",
        "\n",
        "q2 = ask(\"How does Maia-2’s skill-aware attention mechanism adjust move predictions when modeling players of different skill levels?\")  # Maia-2\n",
        "\n",
        "q3 = ask(\"What types of datasets were used to train ChessGPT, and how do the game, language, and mixed datasets each contribute to improving its performance?\")  # ChessGPT\n",
        "\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "\n",
        "os.makedirs(\"logs\", exist_ok=True)\n",
        "with open('logs/results_e5small_500_100.json', 'w') as f:\n",
        "    json.dump([q1, q2, q3], f, indent=2)\n",
        "print('Saved logs/results_e5small_500_100.json')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUv5CT5DVpOW",
        "outputId": "353ab95e-66de-4894-e65f-7226a16b55f2"
      },
      "id": "LUv5CT5DVpOW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Q: What role does Stockfish 16 play in annotating the ChessBench dataset, and how do these annotations support amortized planning models in learning better policies?\n",
            "A: Stockfish 16 plays a crucial role in annotating the ChessBench dataset by providing high-quality, expert-level evaluations for each board state. Specifically, it annotates:\n",
            "\n",
            "1.  **State-values:** The value of a given board state.\n",
            "2.  **Best-action:** The optimal move to make from that board state.\n",
            "3.  **Action-values:** The value for *all legal actions* possible in each board state (amounting to 15 billion data points).\n",
            "\n",
            "These annotations support amortized planning models in learning better policies by serving as the ground truth for supervised training. By training on this massive dataset, models (such as feed-forward transformers) can \"distill an approximation of Stockfish 16, a complex planning algorithm,\" into a network that can predict state-values, best-actions, and action-values. This allows the models to learn strong chess policies that generalize well to unseen board states, effectively amortizing the complex planning process of Stockfish 16 into a faster, feed-forward prediction.\n",
            "\n",
            "Sources:\n",
            "[1] Chess Bench with Stockfish Paper.pdf :: series of benchmark results through our models, ablations, and comparisons with Stock- fish 16, Leela Chess Zero, and AlphaZero, and their searchless policy/val...\n",
            "[2] Chess Bench with Stockfish Paper.pdf :: 6 Conclusion Our paper introduces ChessBench, a large-scale, open source benchmark dataset for chess, and shows the feasibility of distilling an approximation o...\n",
            "[3] Chess Bench with Stockfish Paper.pdf :: better optimization, data augmentation, etc.) might be needed instead of even larger scale. Our main contributions are: • We introduce ChessBench, a large-scale...\n",
            "\n",
            "Q: How does Maia-2’s skill-aware attention mechanism adjust move predictions when modeling players of different skill levels?\n",
            "A: Maia-2's skill-aware attention mechanism adjusts move predictions by:\n",
            "\n",
            "*   **Adapting predictions:** It accounts for the skill levels of both the active player and the opponent player.\n",
            "*   **Adjusting its focus:** The attention mechanism reflects the strategic considerations and positional understanding specific to players at different skill levels.\n",
            "*   **Prioritizing relevant features:** This adjustment allows Maia-2 to adaptively prioritize features of the chess position that are more relevant to the skill levels involved, thereby enhancing the model’s contextual sensitivity.\n",
            "\n",
            "Sources:\n",
            "[1] Maia-2 Paper.pdf :: with skill-aware attention enables Maia-2 to adapt its predictions to account for the skill levels of both the active player and the opponent player, so that va...\n",
            "[2] Maia-2 Paper.pdf :: k, the attention mechanism can adjust its focus to reflect the strategic considerations and positional understanding of players at different skill levels. This ...\n",
            "[3] Maia-2 Paper.pdf :: effectiveness of our unified modeling approach across diverse skill levels. Adaptive move predictions. We now evaluate Maia-2’s ability to predict compare acros...\n",
            "\n",
            "Q: What types of datasets were used to train ChessGPT, and how do the game, language, and mixed datasets each contribute to improving its performance?\n",
            "A: ChessGPT was trained using a large-scale game and language dataset for chess, which comprises several types:\n",
            "\n",
            "1.  **Game dataset:** This dataset consists of numerous game replay data from online chess databases, recording matches played by both human players and chess engines of varying skill levels. This contributes by teaching the model the actual mechanics, strategies, and outcomes of chess games.\n",
            "2.  **Language dataset:** This dataset encapsulates chess knowledge in a natural language format, principally recording chess-associated knowledge, analyses, discussions, and news. This helps the model understand chess concepts, terminology, and human commentary.\n",
            "3.  **Mixed Game-Language dataset:** This dataset offers the most straightforward interrelated data, including articles, discussions, or commentary (language) directly linked to specific chess game replays (game). This is crucial for improving performance by allowing the model to learn from the interplay between game actions and human interpretation or analysis, connecting the \"what happened\" with the \"why it happened\" or \"what it means.\"\n",
            "4.  **Instruction-tuning and conversation dataset:** This dataset consists of instruction data and is designed for fine-tuning models for conversational abilities related to chess.\n",
            "\n",
            "The combination of these datasets allows ChessGPT to learn from a mixture of raw replay data (game) and human language knowledge (language and mixed), enabling it to understand both the practical aspects of chess and the human discourse surrounding it. The mixed game-language dataset, in particular, helps bridge the gap between game states and natural language explanations, fostering a deeper, more integrated understanding.\n",
            "\n",
            "Sources:\n",
            "[1] Chess GPT Paper.pdf :: format, as well as a mixed game-language dataset, which offers the most straightforward interrelated data including articles, discussion, or commentary (languag...\n",
            "[2] Chess GPT Paper.pdf :: In this section we will describe several potential directions based on our dataset. 1. Dataset Augmentation and Fine-tuning: Researchers can explore dataset aug...\n",
            "[3] Chess GPT Paper.pdf :: online chess match replay data involving worldwide human players and chess engines of varying skill levels. (2) The Language dataset, principally recording ches...\n",
            "Saved logs/results_e5small_500_100.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment: e5-small-v2 | chunk_size=300, overlap=50\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mzIyncufGM0B"
      },
      "id": "mzIyncufGM0B"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "103a4174",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "103a4174",
        "outputId": "bbe6a5a4-085b-4b18-a26e-27e7c0dd6128"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved reproduce_artifacts/rag_run_config_e5small_300_50.json\n"
          ]
        }
      ],
      "source": [
        "# Experiment: e5-small-v2 | chunk_size=300, overlap=50\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "import google.generativeai as genai\n",
        "import os, getpass, pathlib\n",
        "\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
        "splits = splitter.split_documents(docs)\n",
        "emb = SentenceTransformerEmbeddings(model_name=\"intfloat/e5-small-v2\")\n",
        "vs = Chroma.from_documents(splits, embedding=emb, persist_directory=\"./chroma_e5small_300_50\")\n",
        "retriever = vs.as_retriever()\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.2, google_api_key=os.environ['GOOGLE_API_KEY'])\n",
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True)\n",
        "\n",
        "\n",
        "rag_run_config = {\n",
        "    \"chunk_size\": 300,\n",
        "    \"chunk_overlap\": 50,\n",
        "    \"embedding_model\": \"intfloat/e5-small-v2\",\n",
        "    \"llm\": \"gemini-2.5-flash\",\n",
        "    \"retriever_k\": 4\n",
        "}\n",
        "\n",
        "filename = \"reproduce_artifacts/rag_run_config_e5small_300_50.json\"\n",
        "with open(filename, \"w\") as f:\n",
        "    json.dump(rag_run_config, f, indent=2)\n",
        "print(f\"Saved {filename}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "q1 = ask(\"What role does Stockfish 16 play in annotating the ChessBench dataset, and how do these annotations support amortized planning models in learning better policies?\")  # ChessBench\n",
        "\n",
        "q2 = ask(\"How does Maia-2’s skill-aware attention mechanism adjust move predictions when modeling players of different skill levels?\")  # Maia-2\n",
        "\n",
        "q3 = ask(\"What types of datasets were used to train ChessGPT, and how do the game, language, and mixed datasets each contribute to improving its performance?\")  # ChessGPT\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import json\n",
        "import os\n",
        "\n",
        "os.makedirs(\"logs\", exist_ok=True)\n",
        "with open('logs/results_e5small_300_50.json', 'w') as f:\n",
        "    json.dump([q1, q2, q3], f, indent=2)\n",
        "print('Saved logs/results_e5small_300_50.json')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26jCCmGSVsqm",
        "outputId": "b415a912-9725-426b-8963-e1d7883b67d4"
      },
      "id": "26jCCmGSVsqm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Q: What role does Stockfish 16 play in annotating the ChessBench dataset, and how do these annotations support amortized planning models in learning better policies?\n",
            "A: Stockfish 16 plays a crucial role in annotating the ChessBench dataset by providing **state-values** for 530 million board states.\n",
            "\n",
            "These annotations support amortized planning models in learning better policies by:\n",
            "*   Providing expert-derived \"state-values\" which are useful from a reinforcement learning perspective.\n",
            "*   Facilitating **policy learning** and **value function learning**, allowing models to learn from Stockfish 16's complex planning algorithm. This essentially helps in distilling an approximation of Stockfish 16 into searchless policy/value networks.\n",
            "\n",
            "Sources:\n",
            "[1] Chess Bench with Stockfish Paper.pdf :: 6 Conclusion Our paper introduces ChessBench, a large-scale, open source benchmark dataset for chess, and shows the feasibility of distilling an approximation o...\n",
            "[2] Chess Bench with Stockfish Paper.pdf :: better optimization, data augmentation, etc.) might be needed instead of even larger scale. Our main contributions are: • We introduce ChessBench, a large-scale...\n",
            "[3] Chess Bench with Stockfish Paper.pdf :: code at https://github.com/google-deepmind/searchless_chess, and provide a series of benchmark results through our models, ablations, and comparisons with Stock...\n",
            "\n",
            "Q: How does Maia-2’s skill-aware attention mechanism adjust move predictions when modeling players of different skill levels?\n",
            "A: Maia-2's skill-aware attention mechanism adjusts move predictions by adapting its focus to reflect the strategic considerations and positional understanding of players at different skill levels. This allows it to adaptively prioritize features of the chess position that are more relevant to a player of a specific skill level, accounting for both the active player's and the opponent's skill levels.\n",
            "\n",
            "Sources:\n",
            "[1] Maia-2 Paper.pdf :: with skill-aware attention enables Maia-2 to adapt its predictions to account for the skill levels of both the active player and the opponent player, so that va...\n",
            "[2] Maia-2 Paper.pdf :: skill level bears little resemblance to its understanding of the next. In reality, players move from one skill level to another by making small, consistent adju...\n",
            "[3] Maia-2 Paper.pdf :: k, the attention mechanism can adjust its focus to reflect the strategic considerations and positional understanding of players at different skill levels. This ...\n",
            "\n",
            "Q: What types of datasets were used to train ChessGPT, and how do the game, language, and mixed datasets each contribute to improving its performance?\n",
            "A: The datasets used to train ChessGPT are:\n",
            "*   **Game dataset**\n",
            "*   **Language dataset**\n",
            "*   **Mixed dataset**\n",
            "*   **Conversation dataset**\n",
            "\n",
            "While the text describes the content of the game, language, and mixed datasets (e.g., the Language dataset records chess-associated knowledge and discussions, the Mixed dataset incorporates both game data and natural language elements like game analysis), it does not explicitly detail how each of these datasets *specifically contributes to improving ChessGPT's performance*. It only states that ChessGPT leverages these datasets.\n",
            "\n",
            "Sources:\n",
            "[1] Chess GPT Paper.pdf :: skill levels. (2) The Language dataset, principally recording chess-associated knowledge, analyses, discussions, and news in the form of natural language (3) Th...\n",
            "[2] Chess GPT Paper.pdf :: format, as well as a mixed game-language dataset, which offers the most straightforward interrelated data including articles, discussion, or commentary (languag...\n",
            "[3] Chess GPT Paper.pdf :: Data: Our dataset is organized into four categories: game, language, mixed, and conversation datasets. Model: Leveraging this rich dataset, we present two model...\n",
            "Saved logs/results_e5small_300_50.json\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}